{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nckHxo2X9omh"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsOZ64A79xxV"
   },
   "source": [
    "# Install detectron2: (Colab has CUDA 10.1 + torch 1.7)\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yk8r9tbi9v0w",
    "outputId": "3bc120f9-de6c-4ee6-e270-12616bb32501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1 True\n",
      "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !pip install pyyaml==5.1\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version\n",
    "# import opencv as cv\n",
    "import torch\n",
    "# assert torch.__version__.startswith(\"1.7\")\n",
    "# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n",
    "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtimeK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSnnkzBj99Bh"
   },
   "source": [
    "# Setup detectron2 logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWO7b-knuS5b",
    "outputId": "3b549921-6c71-48f9-a5be-311390a3cc5d"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "# from detectron2.utils.logger import setup_logger\n",
    "# setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6YqjyVL-AXP"
   },
   "source": [
    "# Import some common libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dISpi3JRuP0r"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-22fe296ae0e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VETFTisS-E-I"
   },
   "source": [
    "# Import some common detectron2 utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p99N-8kWTrMo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAD9Dv2kuN3g"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHIUeuBHj4o7"
   },
   "source": [
    " # Mount your Google Drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnSnXLdjrlcg"
   },
   "source": [
    "Run the code cell below to link your google drive to this document. It will create a link to permission requests and a verification code that needs entered after initializing the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StQ2jrO-Ckb1",
    "outputId": "ebdf6c4e-99f0-4bd9-f783-ca8cfd1128a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mo_cgwrVsEUH"
   },
   "source": [
    "After mounting the drive, look in the Colab file explorer (at the left side of the browser by default).The shared drive \"garden_imgs\" path should match the string below. **↓**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "d0KFFgM1rG-m"
   },
   "outputs": [],
   "source": [
    "# PATH_TO_IMGS = \"PATH TO garden_img\"\n",
    "PATH_TO_IMGS = \"/content/drive/Shareddrives/Weed_Detection\"  ##SHARED DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bimj-wq6qUPZ",
    "outputId": "a5950f36-0baa-4679-bc88-f09d85e10a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_2.json  1_4.zip   1_7.json  1_9.zip\t2_3.json  2_5.zip   ipynb_checkpoints\n",
      "1_2.zip   1_5.json  1_7.zip   2_1.json\t2_3.zip   2_6.json  Testing_Data\n",
      "1_3.json  1_5.zip   1_8.json  2_1.zip\t2_4.json  2_6.zip\n",
      "1_3.zip   1_6.json  1_8.zip   2_2.json\t2_4.zip   2_7.zip\n",
      "1_4.json  1_6.zip   1_9.json  2_2.zip\t2_5.json  2_8.zip\n"
     ]
    }
   ],
   "source": [
    "!ls $PATH_TO_IMGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbZHXBhz82Mt"
   },
   "source": [
    "**↓** We want to unzip the zipped file we linked to in our previous line of code **↓**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7186_OL9lqoN",
    "outputId": "25eceae5-fcf5-4e0f-da4b-a0e4837b2dbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/Shareddrives/Weed_Detection/Testing_Data/1_1.zip\n",
      "replace frame_000001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!unzip \"/content/drive/Shareddrives/Weed_Detection/Testing_Data/1_1.zip\" \n",
    "!unzip \"/content/drive/Shareddrives/Weed_Detection/1_2.zip\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e9f3IGMXbDe"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIbAM2pv-urF"
   },
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"garden_training_set\", {}, \"/content/drive/Shareddrives/Weed_Detection/1_2.json\", \"/content/\")\n",
    "\n",
    "register_coco_instances(\"garden_testing_set\", {}, \"/content/drive/Shareddrives/Weed_Detection/Testing_Data/1_2.json\", \"/content/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ljbWTX0Wi8E"
   },
   "source": [
    "# Check that the data loaded correctly with visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_E1PJ1h0yTTX"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"garden_training_set\")\n",
    "meta_data = MetadataCatalog.get(\"garden_training_set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpwSuOv7n9vo"
   },
   "source": [
    "#Remove empty annotations from dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8KV-AB1YIKa"
   },
   "outputs": [],
   "source": [
    "dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9rfRQXFYAqX0"
   },
   "outputs": [],
   "source": [
    "dataset_dicts = DatasetCatalog.get(\"garden_training_set\")\n",
    "for entry in dataset_dicts:\n",
    "  print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXdIbiV1jdAv"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = plt.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img, metadata=meta_data, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlqXIXXhW8dA"
   },
   "source": [
    "## Train!\n",
    "\n",
    "Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU, or ~2 minutes on a P100 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7unkuuiqLdqd"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"garden_training_set\",)\n",
    "# cfg.DATASETS.TEST = (\"garden_testing_set\")\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good Learning Rate\n",
    "cfg.SOLVER.MAX_ITER = 300    # iterations. 300 to make sure it runs before we train the full model.\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for starting out (default: 512 for full model)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # only has one class (weed). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfbiXatXO9xi"
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "#Use the final weights generated after successful training for inference  \n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8  # set the testing threshold for this model\n",
    "#Pass the validation dataset\n",
    "cfg.DATASETS.TEST = (\"boardetect_val\", )\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "dataset_dicts = get_board_dicts(\"Text_Detection_Dataset_COCO_Format/val\")\n",
    "for d in random.sample(dataset_dicts, 3):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=board_metadata, \n",
    "                   scale=0.8,\n",
    "                   instance_mode=ColorMode.IMAGE   \n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\")) #Passing the predictions to CPU from the GPU\n",
    "    cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBXeH8UXFcqU"
   },
   "outputs": [],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zA6XGdts-ok0"
   }
